

###数据中的问题

####评论人自身的问题

* 一人多次评论
	
	在该领域不太可能有多次评论
	
* 标注错误

	编辑对评论的打分的偏差很大
	
	1. 平均分的差距 很明显
	2. 1200与600的差距 并不明显
	


###评论质量

* spam detection
	
	介绍

* helpfulness rating

	介绍
	
###Spam detection的解决办法

* link
* n-gram
* reviewer time span
* coping cat

###Helpfulness prediction

####Review

* Review Summarization



* Unsupervised -- coverage

	将最大程度覆盖各种特征的评论进行排序，并按照覆盖的特征多少进行排序。
	
	* Lexicon based
	
	先找到该产品的所有特征，然后对评论进行排序，将问题转移到情感分析中的评价对象和实体识别。
	优点：准确和全面
	
	* key word select

	对全部评论句进行对比计算，利用共现率进行关键词抽取并认定为是特征，将问题转移到特征词提取。
	优点：domain independent
	
	* LDA based
	
	the input is the review corpus and the rating corpus
	
* Supervised

	* User profile 
	
		1. 对用户建模，认为有些用户就是优质评论生产机，而有些用户就是渣渣，于是当优质用户生产新评论时，它有很大几率是好评论。
		2. 对User进行promote，对比Wikipedia，由于那边的评论和内容都是实名制，于是用户会强迫自己去写优质内容，而渣渣用户则不敢在上面瞎写，同时大多是客观事实，于是没有多少臆造空间。而用户评论则不一样，以主观内容为主，提供了臆造空间，并且大多是匿名状态且曝光率并不高，于是造假成本更低。
	
	* User Rating

	采用用户的打分信息进行回归预测，但是这里有几种明显的bias，如early bird。而数据同时显示，确实稀疏。(数据集中数据太少)




####各种存在的问题

* Coverage

如果按照特征的多少进行排序，很容易就造成各种重复。

来个例子

	* Lexicon based
	手工持续添加特征，针对同一个领域还可以接受，若是多个领域就瞎了，需要大量的expert参与
	* Unsupervised
	如何过滤掉没用的东西就很重要，总会有些奇葩的噪音在。
	
* 大量的重复
* 少数特征完全不会被体现


###新的尝试--两步

* 评论聚类

	为了解决上面的两个问题，聚类可以将具有相同特征的评论进行汇总，同时很少被提及的特征也会以孤立点的形式存在。
	既能够识别重复，又能够找到量少的特征
	
	方法：Kmeans，NKmeans

* 评论排序

什么是质量？

* 描述了主要特征
* 表达清晰
* 内容丰富

以Unsupervised的方法为主，通过对句子进行词性和依存句法进行分析，找到潜在的评论对象和评论词，然后对目标词进行统计分析，进而形成lexicon。

然后对每一句话中的特征和情感进行识别并排序，优先特征，然后是情感符合整体趋势的程度。









































































































































































































































































































































































































































































































































































































